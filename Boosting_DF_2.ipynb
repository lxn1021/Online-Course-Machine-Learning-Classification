{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting a decision stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = graphlab.SFrame(\"E:\\\\Machine Learning\\\\U.W\\\\Classification\\\\lending-club-data.gl/\")\n",
    "loans.save(\"E:\\\\Machine Learning\\\\U.W\\\\Classification\\\\lending-club-data.csv\", format=\"csv\")\n",
    "loans = pd.read_csv(\"E:\\\\Machine Learning\\\\U.W\\\\Classification\\\\lending-club-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>collections_12_mths_zero</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>final_d</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_record_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.14350</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.39320</td>\n",
       "      <td>20161201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.25955</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27585</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075269</td>\n",
       "      <td>1311441</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.90</td>\n",
       "      <td>156.46</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.21533</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599       5000         5000             4975   36 months   \n",
       "1  1077430    1314167       2500         2500             2500   60 months   \n",
       "2  1077175    1313524       2400         2400             2400   36 months   \n",
       "3  1076863    1277178      10000        10000            10000   36 months   \n",
       "4  1075269    1311441       5000         5000             5000   36 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade          ...          sub_grade_num  \\\n",
       "0     10.65       162.87     B        B2          ...                    0.4   \n",
       "1     15.27        59.83     C        C4          ...                    0.8   \n",
       "2     15.96        84.33     C        C5          ...                    1.0   \n",
       "3     13.49       339.31     C        C1          ...                    0.2   \n",
       "4      7.90       156.46     A        A4          ...                    0.8   \n",
       "\n",
       "  delinq_2yrs_zero pub_rec_zero  collections_12_mths_zero short_emp  \\\n",
       "0              1.0          1.0                       1.0         0   \n",
       "1              1.0          1.0                       1.0         1   \n",
       "2              1.0          1.0                       1.0         0   \n",
       "3              1.0          1.0                       1.0         0   \n",
       "4              1.0          1.0                       1.0         0   \n",
       "\n",
       "  payment_inc_ratio          final_d last_delinq_none last_record_none  \\\n",
       "0           8.14350  20141201T000000                1                1   \n",
       "1           2.39320  20161201T000000                1                1   \n",
       "2           8.25955  20141201T000000                1                1   \n",
       "3           8.27585  20141201T000000                0                1   \n",
       "4           5.21533  20141201T000000                1                1   \n",
       "\n",
       "  last_major_derog_none  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the target and the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"grade\", \"term\", \"home_ownership\", \"emp_length\"]\n",
    "\n",
    "loans[\"safe_loans\"] = loans[\"bad_loans\"].apply(lambda x: +1 if x==0 else -1)\n",
    "loans = loans.drop([\"bad_loans\"], axis=1)\n",
    "target = \"safe_loans\"\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample dataset to make sure classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of safe loans                : 0.5\n",
      "Percentage of risky loans               : 0.5\n",
      "Total number of loans in our new dataset: 46300\n"
     ]
    }
   ],
   "source": [
    "safe_loans_raw = loans[loans[target] == 1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "risky_loans = risky_loans_raw\n",
    "safe_loans = safe_loans_raw.sample(frac=percentage, random_state=42)\n",
    "loans_data = risky_loans.append(safe_loans)\n",
    "\n",
    "print \"Percentage of safe loans                :\", len(safe_loans)/float(len(loans_data))\n",
    "print \"Percentage of risky loans               :\", len(risky_loans)/float(len(loans_data))\n",
    "print \"Total number of loans in our new dataset:\", len(loans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform categorical data into binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_data = risky_loans.append(safe_loans)\n",
    "\n",
    "loans_data = pd.get_dummies(loans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['grade_A', 'grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F',\n",
       "       'grade_G', 'term_ 36 months', 'term_ 60 months',\n",
       "       'home_ownership_MORTGAGE', 'home_ownership_OTHER',\n",
       "       'home_ownership_OWN', 'home_ownership_RENT', 'emp_length_1 year',\n",
       "       'emp_length_10+ years', 'emp_length_2 years', 'emp_length_3 years',\n",
       "       'emp_length_4 years', 'emp_length_5 years', 'emp_length_6 years',\n",
       "       'emp_length_7 years', 'emp_length_8 years', 'emp_length_9 years',\n",
       "       'emp_length_< 1 year'], dtype=object)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = loans_data.columns.values\n",
    "features = features[features != \"safe_loans\"]\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(loans_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print len(train_data)/len(loans_data)\n",
    "print len(test_data)/len(loans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted error definition\n",
    "\n",
    "$$\n",
    "\\mathrm{E}(\\mathbf{\\alpha}, \\mathbf{\\hat{y}}) = \\frac{\\sum_{i=1}^{n} \\alpha_i \\times 1[y_i \\neq \\hat{y_i}]}{\\sum_{i=1}^{n} \\alpha_i}\n",
    "$$\n",
    "\n",
    "\n",
    "### Write a function to compute weight of mistakes\n",
    "\n",
    "$$\n",
    "\\mathrm{WM}(\\mathbf{\\alpha}, \\mathbf{\\hat{y}}) = \\sum_{i=1}^{n} \\alpha_i \\times 1[y_i \\neq \\hat{y_i}].\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{E}(\\mathbf{\\alpha}, \\mathbf{\\hat{y}}) = \\frac{\\mathrm{WM}(\\mathbf{\\alpha}, \\mathbf{\\hat{y}})}{\\sum_{i=1}^{n} \\alpha_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_node_weighted_mistakes(labels_in_node, data_weights):\n",
    "    # Sum the weights of all entries with label +1.\n",
    "    arr1 = np.array(labels_in_node == +1)\n",
    "    total_weight_positive = sum(data_weights[list(arr1)])\n",
    "    \n",
    "    # Weight of mistakes for predicting all -1's is equal to the sum above.\n",
    "    weighted_mistakes_all_negative = total_weight_positive\n",
    "    \n",
    "    # Sum the weights of all entries with label -1.\n",
    "    arr2 = np.array(labels_in_node == -1)\n",
    "    total_weight_negative = sum(data_weights[list(arr2)])\n",
    "    \n",
    "    # Weight of mistakes for predicting all +1's is equal to the sum above.\n",
    "    weighted_mistakes_all_positive = total_weight_negative\n",
    "    \n",
    "    # Return the tuple (weight, class_label) representing the lower of the two weights\n",
    "    # class_label should be an integer of value +1 or -1.\n",
    "    # If the two weights are identical, return (weighted_mistakes_all_positive, +1)\n",
    "    if weighted_mistakes_all_negative < weighted_mistakes_all_positive:\n",
    "        return (weighted_mistakes_all_negative, -1)\n",
    "    else:\n",
    "        return (weighted_mistakes_all_positive, +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to pick best feature to split on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target, data_weights):\n",
    "\n",
    "    best_feature = None\n",
    "    best_error = float(\"+inf\")\n",
    "    num_points = float(len(data))\n",
    "    \n",
    "    \n",
    "    for feature in features:\n",
    "        \n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "        \n",
    "        arr1 = np.array(data[feature] == 0)\n",
    "        arr2 = np.array(data[feature] == 1)\n",
    "        \n",
    "        left_data_weights = data_weights[list(arr1)]\n",
    "        right_data_weights = data_weights[list(arr2)]\n",
    "        \n",
    "        left_weighted_mistakes, left_class = intermediate_node_weighted_mistakes(left_split[target], left_data_weights)\n",
    "        right_weighted_mistakes, right_class = intermediate_node_weighted_mistakes(right_split[target], right_data_weights)\n",
    "        \n",
    "        error = (left_weighted_mistakes + right_weighted_mistakes) / num_points\n",
    "        \n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "            \n",
    "\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values, data_weights):\n",
    "    leaf = {\"splitting_feature\": None,\n",
    "           \"is_leaf\": True}\n",
    "    \n",
    "    weighted_error, best_class = intermediate_node_weighted_mistakes(target_values, data_weights)\n",
    "    \n",
    "    leaf[\"prediction\"] = best_class\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_decision_tree_create(data, features, target, data_weights, current_depth = 1, max_depth = 10):\n",
    "    remaining_features = features[:]  \n",
    "    target_values = data[target]\n",
    "    print \"---------------------------------------------------------------------\"\n",
    "    print \"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values))\n",
    "    \n",
    "    \n",
    "    if intermediate_node_weighted_mistakes(target_values, data_weights)[0] <= 1e-15:\n",
    "        print \"Stopping condition 1 reached.\"\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    if remaining_features == []:\n",
    "        print \"Stopping condition 2 reached.\"\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    if current_depth > max_depth:\n",
    "        print \"Reached maximum depth. Stopping for now.\"\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    \n",
    "    splitting_feature = best_splitting_feature(data, features, target, data_weights)\n",
    "    remaining_features = remaining_features[remaining_features != splitting_feature]\n",
    "    \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    arr1 = np.array(data[splitting_feature] == 0)\n",
    "    arr2 = np.array(data[splitting_feature] == 1)\n",
    "    \n",
    "    left_data_weights = data_weights[list(arr1)]\n",
    "    right_data_weights = data_weights[list(arr2)]\n",
    "    \n",
    "    print \"Split on feature %s. (%s, %s)\" % (splitting_feature, len(left_split), len(right_split))\n",
    "    \n",
    "    \n",
    "    if len(left_split) == len(data):\n",
    "        print \"Creating leaf node.\"\n",
    "        return create_leaf(left_split[target], data_weights)\n",
    "    if len(right_split) == len(data):\n",
    "        print \"Creating leaf node.\"\n",
    "        return create_leaf(right_split[target], data_weights)\n",
    "    \n",
    "\n",
    "    left_tree = weighted_decision_tree_create(left_split, remaining_features, target, left_data_weights, current_depth + 1, max_depth)\n",
    "    right_tree = weighted_decision_tree_create(right_split, remaining_features, target, right_data_weights, current_depth + 1, max_depth)\n",
    "    \n",
    "    return {\"is_leaf\": False,\n",
    "           \"prediction\": None,\n",
    "           \"splitting_feature\": splitting_feature,\n",
    "           \"left\": left_tree,\n",
    "           \"right\": right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree[\"is_leaf\"]:\n",
    "        return 1\n",
    "    \n",
    "    return 1 + count_nodes(tree[\"left\"]) + count_nodes(tree[\"right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with a weighted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):\n",
    "    if tree[\"is_leaf\"]:\n",
    "        if annotate:\n",
    "            print \"At leaf, predicting %s\" % tree[\"prediction\"]\n",
    "        return tree[\"prediction\"]\n",
    "    else:\n",
    "        split_feature_value = x[tree[\"splitting_feature\"]]\n",
    "        if annotate:\n",
    "            print \"Split on %s = %s\" % (tree[\"splitting_feature\"], split_feature_value)\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree[\"left\"], x, annotate)\n",
    "        else:\n",
    "            return classify(tree[\"right\"], x, annotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the tree\n",
    "\n",
    "$$\n",
    "\\mbox{classification error} = \\frac{\\mbox{# mistakes}}{\\mbox{# all data points}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    prediction = data.apply(lambda x: classify(tree, x))\n",
    "    \n",
    "    return (prediction != data[target]).sum() / float(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing your own Adaboost (on decision stumps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Start with unweighted data with $\\alpha_j = 1$\n",
    "\n",
    "2\\. For t = 1,...T:\n",
    "  * Learn $f_t(x)$ with data weights $\\alpha_j$\n",
    "  * Compute coefficient $\\hat{w}_t$:\n",
    "     $$\\hat{w}_t = \\frac{1}{2}\\ln{\\left(\\frac{1- \\mbox{E}(\\mathbf{\\alpha}, \\mathbf{\\hat{y}})}{\\mbox{E}(\\mathbf{\\alpha}, \\mathbf{\\hat{y}})}\\right)}$$\n",
    "  * Re-compute weights $\\alpha_j$:\n",
    "     $$\\alpha_j \\gets \\begin{cases}\n",
    "     \\alpha_j \\exp{(-\\hat{w}_t)} & \\text{ if }f_t(x_j) = y_j\\\\\n",
    "     \\alpha_j \\exp{(\\hat{w}_t)} & \\text{ if }f_t(x_j) \\neq y_j\n",
    "     \\end{cases}$$\n",
    "  * Normalize weights $\\alpha_j$:\n",
    "      $$\\alpha_j \\gets \\frac{\\alpha_j}{\\sum_{i=1}^{N}{\\alpha_i}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from math import exp\n",
    "\n",
    "def adaboost_with_tree_stumps(data, features, target, num_tree_stumps):\n",
    "\n",
    "    alpha = np.array([1.]*len(data))\n",
    "    weights = []\n",
    "    tree_stumps = []\n",
    "    target_values = data[target]\n",
    "    \n",
    "    for t in xrange(num_tree_stumps):\n",
    "        print \"=====================================================\"\n",
    "        print \"Adaboost Iteration %d\" % t\n",
    "        print \"=====================================================\"\n",
    "        \n",
    "        tree_stump = weighted_decision_tree_create(data, features, target, data_weights=alpha, max_depth=1)\n",
    "        tree_stumps.append(tree_stump)\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(len(data)):\n",
    "            predictions.append(classify(tree_stump, data.iloc[i]))\n",
    "        \n",
    "        is_correct = predictions == target_values\n",
    "        is_wrong   = predictions != target_values\n",
    "        \n",
    "        weighted_error = sum(alpha[is_wrong])/sum(alpha)\n",
    "        \n",
    "        weight = 1/2 * log((1 - weighted_error)/weighted_error)\n",
    "        weights.append(weight)\n",
    "        \n",
    "        adjustment = is_correct.apply(lambda is_correct: exp(-weight) if is_correct else exp(weight))\n",
    "\n",
    "        alpha = (alpha * adjustment)/float(sum(alpha))\n",
    "\n",
    "        \n",
    "    return weights, tree_stumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking your Adaboost code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature term_ 36 months. (9199, 27841)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9199 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27841 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_A. (31960, 5080)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (31960 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5080 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, features, target, num_tree_stumps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15312961962530405, 0.1795979037893667]\n"
     ]
    }
   ],
   "source": [
    "print stump_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a boosted ensemble of 10 stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature term_ 36 months. (9199, 27841)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9199 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27841 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_A. (31960, 5080)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (31960 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5080 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_D. (30368, 6672)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30368 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6672 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_B. (26721, 10319)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26721 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10319 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature home_ownership_RENT. (20329, 16711)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (20329 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (16711 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_E. (33567, 3473)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33567 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3473 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_A. (31960, 5080)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (31960 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5080 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_F. (35299, 1741)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35299 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_A. (31960, 5080)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (31960 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5080 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_F. (35299, 1741)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35299 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1741 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, features, target, num_tree_stumps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "$$\n",
    "\\hat{y} = sign\\left(\\sum_{t=1}^T \\hat{w}_t f_t(x)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_adaboost(stump_weights, tree_stumps, data):\n",
    "    scores = np.array([0.] * len(data))\n",
    "    \n",
    "    for i, tree_stump in enumerate(tree_stumps):\n",
    "        predictions = []\n",
    "        for j in range(len(data)):\n",
    "            predictions.append(classify(tree_stump, data.iloc[j]))\n",
    "            \n",
    "        scores += (stump_weights[i] * np.array(predictions))\n",
    "        \n",
    "    \n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > 0:\n",
    "            scores[i] = 1\n",
    "        else:\n",
    "            scores[i] = -1\n",
    "    \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 10-component ensemble = 0.61879049676\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_adaboost(stump_weights, tree_stumps, test_data)\n",
    "accuracy = sum(test_data[target] == predictions)/len(test_data)\n",
    "\n",
    "print \"Accuracy of 10-component ensemble = %s\" % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15312961962530405,\n",
       " 0.1795979037893667,\n",
       " 0.1002299872370041,\n",
       " 0.07750274938870685,\n",
       " 0.0728740530879282,\n",
       " 0.047065837472011054,\n",
       " 0.054688932558598,\n",
       " 0.042727718186904795,\n",
       " 0.028386567488876684,\n",
       " 0.018877673583882974]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stump_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature term_ 36 months. (9199, 27841)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9199 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27841 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_A. (31960, 5080)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (31960 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5080 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_D. (30368, 6672)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30368 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6672 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_B. (26721, 10319)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26721 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10319 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature home_ownership_RENT. (20329, 16711)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (20329 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (16711 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_E. (33567, 3473)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33567 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3473 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_A. (31960, 5080)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (31960 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5080 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_F. (35299, 1741)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35299 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_A. (31960, 5080)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (31960 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5080 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_F. (35299, 1741)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35299 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 10\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_D. (30368, 6672)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30368 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6672 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 11\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_B. (26721, 10319)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26721 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10319 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 12\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_F. (35299, 1741)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35299 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 13\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_C. (27723, 9317)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27723 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9317 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 14\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature term_ 36 months. (9199, 27841)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9199 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27841 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 15\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_E. (33567, 3473)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33567 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3473 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 16\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_A. (31960, 5080)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (31960 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5080 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 17\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_F. (35299, 1741)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35299 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1741 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 18\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature emp_length_2 years. (33529, 3511)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33529 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3511 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 19\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_G. (36602, 438)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36602 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (438 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 20\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_B. (26721, 10319)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26721 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10319 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 21\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature term_ 36 months. (9199, 27841)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9199 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27841 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 22\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_G. (36602, 438)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36602 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (438 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 23\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_D. (30368, 6672)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30368 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6672 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 24\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature home_ownership_OWN. (33948, 3092)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33948 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3092 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 25\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_A. (31960, 5080)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (31960 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5080 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 26\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_G. (36602, 438)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36602 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (438 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 27\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature emp_length_10+ years. (26861, 10179)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26861 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10179 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 28\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n",
      "Split on feature grade_C. (27723, 9317)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (27723 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9317 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 29\n",
      "=====================================================\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37040 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature grade_G. (36602, 438)\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (36602 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "---------------------------------------------------------------------\n",
      "Subtree, depth = 2 (438 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, features, target, num_tree_stumps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing training error at the end of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training error = 0.424028077754\n",
      "Iteration 2, training error = 0.431398488121\n",
      "Iteration 3, training error = 0.398110151188\n",
      "Iteration 4, training error = 0.383531317495\n",
      "Iteration 5, training error = 0.384638228942\n",
      "Iteration 6, training error = 0.384692224622\n",
      "Iteration 7, training error = 0.382910367171\n",
      "Iteration 8, training error = 0.384692224622\n",
      "Iteration 9, training error = 0.381695464363\n",
      "Iteration 10, training error = 0.383477321814\n",
      "Iteration 11, training error = 0.381695464363\n",
      "Iteration 12, training error = 0.381695464363\n",
      "Iteration 13, training error = 0.381695464363\n",
      "Iteration 14, training error = 0.381695464363\n",
      "Iteration 15, training error = 0.381695464363\n",
      "Iteration 16, training error = 0.381695464363\n",
      "Iteration 17, training error = 0.381695464363\n",
      "Iteration 18, training error = 0.381695464363\n",
      "Iteration 19, training error = 0.381695464363\n",
      "Iteration 20, training error = 0.381695464363\n",
      "Iteration 21, training error = 0.382127429806\n",
      "Iteration 22, training error = 0.382127429806\n",
      "Iteration 23, training error = 0.3813174946\n",
      "Iteration 24, training error = 0.381155507559\n",
      "Iteration 25, training error = 0.381128509719\n",
      "Iteration 26, training error = 0.381074514039\n",
      "Iteration 27, training error = 0.381101511879\n",
      "Iteration 28, training error = 0.38129049676\n",
      "Iteration 29, training error = 0.381047516199\n",
      "Iteration 30, training error = 0.38129049676\n"
     ]
    }
   ],
   "source": [
    "error_all = []\n",
    "\n",
    "for n in xrange(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], train_data)\n",
    "    error = sum(train_data[target] != predictions)/len(train_data)\n",
    "    error_all.append(error)\n",
    "    \n",
    "    print \"Iteration %s, training error = %s\" % (n, error_all[n-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing training error vs number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 7, 5\n",
    "\n",
    "plt.plot(range(1, 31), error_all, \"-\", linewidth=4.0, label=\"Training error\")\n",
    "plt.title(\"Performance of Adaboost ensemble\")\n",
    "plt.xlabel(\"# of iterations\")\n",
    "plt.ylabel(\"Classification error\")\n",
    "plt.legend(loc=\"best\", prop={\"size\":15})\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, test error = 0.419330453564\n",
      "Iteration 2, test error = 0.427321814255\n",
      "Iteration 3, test error = 0.397732181425\n",
      "Iteration 4, test error = 0.378725701944\n",
      "Iteration 5, test error = 0.382505399568\n",
      "Iteration 6, test error = 0.382613390929\n",
      "Iteration 7, test error = 0.3813174946\n",
      "Iteration 8, test error = 0.382613390929\n",
      "Iteration 9, test error = 0.379913606911\n",
      "Iteration 10, test error = 0.38120950324\n",
      "Iteration 11, test error = 0.379913606911\n",
      "Iteration 12, test error = 0.379913606911\n",
      "Iteration 13, test error = 0.379913606911\n",
      "Iteration 14, test error = 0.379913606911\n",
      "Iteration 15, test error = 0.379913606911\n",
      "Iteration 16, test error = 0.379913606911\n",
      "Iteration 17, test error = 0.379913606911\n",
      "Iteration 18, test error = 0.379913606911\n",
      "Iteration 19, test error = 0.379913606911\n",
      "Iteration 20, test error = 0.379913606911\n",
      "Iteration 21, test error = 0.380345572354\n",
      "Iteration 22, test error = 0.380345572354\n",
      "Iteration 23, test error = 0.381749460043\n",
      "Iteration 24, test error = 0.379589632829\n",
      "Iteration 25, test error = 0.379589632829\n",
      "Iteration 26, test error = 0.379373650108\n",
      "Iteration 27, test error = 0.379589632829\n",
      "Iteration 28, test error = 0.380885529158\n",
      "Iteration 29, test error = 0.379373650108\n",
      "Iteration 30, test error = 0.380885529158\n"
     ]
    }
   ],
   "source": [
    "test_error_all = []\n",
    "\n",
    "for n in xrange(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], test_data)\n",
    "    error = sum(test_data[target] != predictions)/float(len(test_data))\n",
    "    test_error_all.append(error)\n",
    "    \n",
    "    print \"Iteration %s, test error = %s\" % (n, test_error_all[n-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize both the training and test errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 7, 5\n",
    "\n",
    "plt.plot(range(1, 31), error_all, \"-\", linewidth=4.0, label=\"Training error\")\n",
    "plt.plot(range(1, 31), test_error_all, \"-\", linewidth=4.0, label=\"Test error\")\n",
    "\n",
    "plt.title(\"Performance of Adaboost ensemble\")\n",
    "plt.xlabel(\"# of iterations\")\n",
    "plt.ylabel(\"Classification error\")\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "plt.legend(loc=\"best\", prop={\"size\": 15})\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
